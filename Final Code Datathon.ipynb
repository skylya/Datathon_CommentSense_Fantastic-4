{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32125760",
   "metadata": {},
   "source": [
    "# Data Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "7c2eef06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "c9f6af5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP features (optional later)\n",
    "from textblob import TextBlob   # for sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "38bba93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38933380",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import data\n",
    "data=pd.read_csv(r\"D:\\Datathon\\DatasetCombined\\CombinedComments.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "ae7d1719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source.Name</th>\n",
       "      <th>kind</th>\n",
       "      <th>commentId</th>\n",
       "      <th>channelId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>parentCommentId</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comments1.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>1781382</td>\n",
       "      <td>14492</td>\n",
       "      <td>74288</td>\n",
       "      <td>2032536</td>\n",
       "      <td>PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would ro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16/8/2023 5:48</td>\n",
       "      <td>16/8/2023 5:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comments1.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>289571</td>\n",
       "      <td>14727</td>\n",
       "      <td>79618</td>\n",
       "      <td>3043229</td>\n",
       "      <td>Apply mashed potato juice and mixed it with curd</td>\n",
       "      <td>3198066.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2/10/2023 21:08</td>\n",
       "      <td>2/10/2023 21:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comments1.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>569077</td>\n",
       "      <td>3314</td>\n",
       "      <td>51826</td>\n",
       "      <td>917006</td>\n",
       "      <td>69 missed calls from marsüëΩ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>31/5/2024 20:03</td>\n",
       "      <td>31/5/2024 20:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comments1.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>2957962</td>\n",
       "      <td>5008</td>\n",
       "      <td>58298</td>\n",
       "      <td>1853470</td>\n",
       "      <td>Baaa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>13/2/2024 23:48</td>\n",
       "      <td>13/2/2024 23:48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comments1.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>673093</td>\n",
       "      <td>21411</td>\n",
       "      <td>1265</td>\n",
       "      <td>2584166</td>\n",
       "      <td>you look like raven from phenomena raven no cap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>16/2/2020 6:28</td>\n",
       "      <td>16/2/2020 6:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Source.Name             kind  commentId  channelId  videoId  authorId  \\\n",
       "0  comments1.csv  youtube#comment    1781382      14492    74288   2032536   \n",
       "1  comments1.csv  youtube#comment     289571      14727    79618   3043229   \n",
       "2  comments1.csv  youtube#comment     569077       3314    51826    917006   \n",
       "3  comments1.csv  youtube#comment    2957962       5008    58298   1853470   \n",
       "4  comments1.csv  youtube#comment     673093      21411     1265   2584166   \n",
       "\n",
       "                                        textOriginal  parentCommentId  \\\n",
       "0  PLEASE LESBIAN FLAG I BEG YOU \\n\\nYou would ro...              NaN   \n",
       "1   Apply mashed potato juice and mixed it with curd        3198066.0   \n",
       "2                         69 missed calls from marsüëΩ              NaN   \n",
       "3                                               Baaa              NaN   \n",
       "4    you look like raven from phenomena raven no cap              NaN   \n",
       "\n",
       "   likeCount      publishedAt        updatedAt  \n",
       "0          0   16/8/2023 5:48   16/8/2023 5:48  \n",
       "1          0  2/10/2023 21:08  2/10/2023 21:08  \n",
       "2          0  31/5/2024 20:03  31/5/2024 20:03  \n",
       "3          0  13/2/2024 23:48  13/2/2024 23:48  \n",
       "4          0   16/2/2020 6:28   16/2/2020 6:28  "
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Take a preview\n",
    "#Displays the first 5 rows of the dataset to get an initial look at the data structure and sample values.\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "c52ff18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source.Name</th>\n",
       "      <th>kind</th>\n",
       "      <th>commentId</th>\n",
       "      <th>channelId</th>\n",
       "      <th>videoId</th>\n",
       "      <th>authorId</th>\n",
       "      <th>textOriginal</th>\n",
       "      <th>parentCommentId</th>\n",
       "      <th>likeCount</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>updatedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>comments5.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>921956</td>\n",
       "      <td>49359</td>\n",
       "      <td>1074</td>\n",
       "      <td>1636820</td>\n",
       "      <td>How she do it agar ma krugi meko sb face p he ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>17/3/2025 12:27</td>\n",
       "      <td>17/3/2025 12:27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>comments5.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>1937406</td>\n",
       "      <td>18820</td>\n",
       "      <td>79136</td>\n",
       "      <td>1976114</td>\n",
       "      <td>–¢–∞–±–∏–π –≥—É–∑–∞–ª—Ä–æ“õ —ç–¥–∏ –∫–∞—Ç—Ç–∞ —ë—à–ª–∏–∫–ª–∞—Ä–≥–∞ —É—Ö—à–∞–¥–∏ üò¢üò¢</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>28/3/2024 3:31</td>\n",
       "      <td>28/3/2024 3:31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>comments5.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>2639661</td>\n",
       "      <td>28652</td>\n",
       "      <td>25093</td>\n",
       "      <td>2644409</td>\n",
       "      <td>Beautiful üòçüòçüòç‚ù§‚ù§‚ù§</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>14/10/2021 15:46</td>\n",
       "      <td>14/10/2021 15:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>comments5.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>1199495</td>\n",
       "      <td>1911</td>\n",
       "      <td>39559</td>\n",
       "      <td>1995432</td>\n",
       "      <td>Chlo√© eau de perfume is feminine and delicate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1/5/2022 13:56</td>\n",
       "      <td>1/5/2022 13:56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>comments5.csv</td>\n",
       "      <td>youtube#comment</td>\n",
       "      <td>4656204</td>\n",
       "      <td>23924</td>\n",
       "      <td>90564</td>\n",
       "      <td>1528784</td>\n",
       "      <td>You can tell by her arms that she works out üòÑüí™üèº</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>16/2/2023 19:28</td>\n",
       "      <td>16/2/2023 19:28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source.Name             kind  commentId  channelId  videoId  authorId  \\\n",
       "9990  comments5.csv  youtube#comment     921956      49359     1074   1636820   \n",
       "9991  comments5.csv  youtube#comment    1937406      18820    79136   1976114   \n",
       "9992  comments5.csv  youtube#comment    2639661      28652    25093   2644409   \n",
       "9993  comments5.csv  youtube#comment    1199495       1911    39559   1995432   \n",
       "9994  comments5.csv  youtube#comment    4656204      23924    90564   1528784   \n",
       "\n",
       "                                           textOriginal  parentCommentId  \\\n",
       "9990  How she do it agar ma krugi meko sb face p he ...              NaN   \n",
       "9991      –¢–∞–±–∏–π –≥—É–∑–∞–ª—Ä–æ“õ —ç–¥–∏ –∫–∞—Ç—Ç–∞ —ë—à–ª–∏–∫–ª–∞—Ä–≥–∞ —É—Ö—à–∞–¥–∏ üò¢üò¢              NaN   \n",
       "9992                                   Beautiful üòçüòçüòç‚ù§‚ù§‚ù§              NaN   \n",
       "9993      Chlo√© eau de perfume is feminine and delicate              NaN   \n",
       "9994    You can tell by her arms that she works out üòÑüí™üèº              NaN   \n",
       "\n",
       "      likeCount       publishedAt         updatedAt  \n",
       "9990          0   17/3/2025 12:27   17/3/2025 12:27  \n",
       "9991          0    28/3/2024 3:31    28/3/2024 3:31  \n",
       "9992          2  14/10/2021 15:46  14/10/2021 15:46  \n",
       "9993          1    1/5/2022 13:56    1/5/2022 13:56  \n",
       "9994          3   16/2/2023 19:28   16/2/2023 19:28  "
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Displays the last 5 rows of the dataset to check how the dataset ends and verify data consistency.\n",
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "e1ee3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9995 entries, 0 to 9994\n",
      "Data columns (total 11 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Source.Name      9995 non-null   object \n",
      " 1   kind             9995 non-null   object \n",
      " 2   commentId        9995 non-null   int64  \n",
      " 3   channelId        9995 non-null   int64  \n",
      " 4   videoId          9995 non-null   int64  \n",
      " 5   authorId         9995 non-null   int64  \n",
      " 6   textOriginal     9995 non-null   object \n",
      " 7   parentCommentId  1088 non-null   float64\n",
      " 8   likeCount        9995 non-null   int64  \n",
      " 9   publishedAt      9995 non-null   object \n",
      " 10  updatedAt        9995 non-null   object \n",
      "dtypes: float64(1), int64(5), object(5)\n",
      "memory usage: 859.1+ KB\n"
     ]
    }
   ],
   "source": [
    "#General information\n",
    "#Provides a summary of the dataset including column names, data types, non-null counts, and memory usage.\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "6082fbe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     9995.000000\n",
      "mean        15.876138\n",
      "std        452.085664\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max      32259.000000\n",
      "Name: likeCount, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Descriptive stats for like_count column only\n",
    "print(data[\"likeCount\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ef1ce0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3125    So stormi is gonna reproduce ta product ok üíÄ o...\n",
      "1441    Are tu bolti hui bilkul bhi achi  nahi lagti  ...\n",
      "4510                             üò± your so beautiful ‚ù§Ô∏è‚ù§Ô∏è\n",
      "Name: textOriginal, dtype: object \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[\"textOriginal\"].sample(3, random_state=42), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79455481",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "65027981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in each column:\n",
      "Source.Name           0\n",
      "kind                  0\n",
      "commentId             0\n",
      "channelId             0\n",
      "videoId               0\n",
      "authorId              0\n",
      "textOriginal          0\n",
      "parentCommentId    8907\n",
      "likeCount             0\n",
      "publishedAt           0\n",
      "updatedAt             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Sums up the number of missing (null) entries in each column.\n",
    "missing_values = data.isnull().sum()\n",
    "\n",
    "#Prints the count of missing values for all columns to decide if imputation is necessary.\n",
    "print(\"Missing values in each column:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d085d5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language distribution:\n",
      "language\n",
      "en         5241\n",
      "unknown     947\n",
      "id          430\n",
      "so          258\n",
      "fr          216\n",
      "de          210\n",
      "af          199\n",
      "ro          194\n",
      "tl          189\n",
      "et          186\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Detect comment beside English\n",
    "\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed = 0  # make results reproducible\n",
    "\n",
    "def detect_language(text):\n",
    "    try:\n",
    "        return detect(text)\n",
    "    except:\n",
    "        return \"unknown\"  # if detection fails\n",
    "\n",
    "# New column for language\n",
    "data[\"language\"] = data[\"textOriginal\"].apply(detect_language)\n",
    "\n",
    "print(\"Language distribution:\")\n",
    "print(data[\"language\"].value_counts().head(10))  # see top 10 detected languages\n",
    "\n",
    "# Filter for English only \n",
    "data = data[data[\"language\"] == \"en\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "12aa9e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clean original text \n",
    "\n",
    "def clean_text(text):\n",
    "    # normalize case\n",
    "    text = str(text).lower()  \n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)  \n",
    "    # remove mentions (@user) \n",
    "    text = re.sub(r'@\\w+', '', text)                      \n",
    "    # hashtags: remove \"#\" but keep the word\n",
    "    text = text.replace(\"#\", \"\")\n",
    "    # keep emojis, remove other unwanted characters\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s\\U0001F600-\\U0001F64F]', '', text)\n",
    "    # Remove repeated punctuation\n",
    "    text = re.sub(r'([!?.,])\\1{2,}', r'\\1', text)\n",
    "    # Remove filler words\n",
    "    text = re.sub(r\"\\b(lol|omg|idk|lmao|haha|hehe)\\b\", \"\", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "data[\"cleaned_comment\"] = data[\"textOriginal\"].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "db86dbc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           textOriginal  \\\n",
      "7093  Next time it happens don't be afraid to ask. M...   \n",
      "784                   It‚Äôs that time of the Ear again üòÇ   \n",
      "3874                           THE HARRY STYLES SOUND ‚ù§   \n",
      "3534  Why do i think latina and baddie mameup is so ...   \n",
      "4051  But u r looks different without makeup mam ......   \n",
      "\n",
      "                                        cleaned_comment  \n",
      "7093  next time it happens dont be afraid to ask men...  \n",
      "784                    its that time of the ear again üòÇ  \n",
      "3874                             the harry styles sound  \n",
      "3534  why do i think latina and baddie mameup is so ...  \n",
      "4051  but u r looks different without makeup mam m t...  \n"
     ]
    }
   ],
   "source": [
    "# Quick check\n",
    "print(data[[\"textOriginal\", \"cleaned_comment\"]].sample(5, random_state=25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1975403",
   "metadata": {},
   "source": [
    "# Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "edc1937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Emoji helper\n",
    "def emoji_sentiment(text):\n",
    "    if any(e in text for e in [\"‚ù§\",\"üíï\",\"üòò\",\"üòä\",\"üòÇ\",\"üòç\"]):\n",
    "        return \"positive\"\n",
    "    if any(e in text for e in [\"üò°\",\"üò†\",\"üíî\",\"üò¢\"]):\n",
    "        return \"negative\"\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "aca1edbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main sentiment function\n",
    "def get_sentiment(text):\n",
    "    # Check emoji sentiment first\n",
    "    emoji_score = emoji_sentiment(text)\n",
    "    if emoji_score:\n",
    "        return emoji_score\n",
    "\n",
    "    # Fallback to TextBlob\n",
    "    analysis = TextBlob(text)\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return \"positive\"\n",
    "    elif analysis.sentiment.polarity < 0:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "85bd6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to dataset\n",
    "data[\"sentiment\"] = data[\"cleaned_comment\"].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "adbea723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Sentiment Results:\n",
      "                                        cleaned_comment sentiment\n",
      "1806        the editing is toptier seriously impressive  positive\n",
      "6831                              me too bro me too üòÇüòÇüòÇ  positive\n",
      "1686          but payton is your best friend is it over  positive\n",
      "9265  could you do a unicorn inspired one \\nlove you...  positive\n",
      "3937  o everyone who says shes a man this comment if...   neutral\n",
      "4659  extremely short you made his eyebrows much sho...  negative\n",
      "8501                              more like xqc haircut  positive\n",
      "7441  you should use the ice cream hair glue brand i...  positive\n",
      "3596                                            urqueen   neutral\n",
      "9232                                        pinkand red   neutral\n"
     ]
    }
   ],
   "source": [
    "# Show some sample results\n",
    "print(\"\\nSample Sentiment Results:\")\n",
    "print(data[[\"cleaned_comment\", \"sentiment\"]].sample(10, random_state=19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "73e7c059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentiment Distribution (Counts):\n",
      "sentiment\n",
      "positive    2825\n",
      "neutral     1795\n",
      "negative     621\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Sentiment Distribution (Percentage):\n",
      "sentiment\n",
      "positive    53.901927\n",
      "neutral     34.249189\n",
      "negative    11.848884\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Show overall distribution\n",
    "print(\"\\nSentiment Distribution (Counts):\")\n",
    "print(data[\"sentiment\"].value_counts())\n",
    "\n",
    "print(\"\\nSentiment Distribution (Percentage):\")\n",
    "print(data[\"sentiment\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2699fe30",
   "metadata": {},
   "source": [
    "# Spam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "93fa7e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Spam distribution:\n",
      "is_spam\n",
      "False    4223\n",
      "True     1018\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_spam(text):\n",
    "    text = str(text).lower().strip()\n",
    "    \n",
    "    # 1. Emoji handling\n",
    "    emoji_list = \"‚ù§üíïüòòüòäüòÇüòçüò°üò†üíîüò¢üòÆüò±ü•∞üî•‚ú®üíØüëçüôè\"\n",
    "    emoji_count = sum(1 for ch in text if ch in emoji_list)\n",
    "\n",
    "    # Emoji-only (spammy)\n",
    "    if emoji_count > 5 and len(text.split()) == 0:\n",
    "        return True\n",
    "\n",
    "    # Emojis dominate (>60% of content is emojis)\n",
    "    if emoji_count > 0 and (emoji_count / max(1, len(text))) > 0.6:\n",
    "        return True\n",
    "\n",
    "    # 2. Suspicious links or promo\n",
    "    if \"http\" in text or \"www\" in text or \"bit.ly\" in text or \"t.me\" in text:\n",
    "        return True\n",
    "\n",
    "    # 3. Very short meaningless comment (only 1-2 chars)\n",
    "    if len(text.split()) == 1 and len(text) < 3:\n",
    "        return True\n",
    "\n",
    "    # 4. Nonsense/random short alphanumeric mix\n",
    "    if re.fullmatch(r\"[a-zA-Z]*[0-9]+[a-zA-Z]*\", text) and len(text) <= 6:\n",
    "        return True\n",
    "\n",
    "    # 5. Spammy phrases (hard rule)\n",
    "    spammy_phrases = [\n",
    "        \"follow me\", \"check my channel\", \"subscribe\", \"buy now\", \n",
    "        \"click here\", \"dm me\", \"promo code\", \"giveaway\", \"visit my page\"\n",
    "    ]\n",
    "    if any(phrase in text for phrase in spammy_phrases):\n",
    "        return True\n",
    "    \n",
    "    # 6. Numbers + symbols together (common spam pattern)\n",
    "    if re.search(r\"[0-9]+.*[$%&]+|[$%&]+.*[0-9]+\", text):\n",
    "        return True\n",
    "    \n",
    "    # 7. Excessive punctuation or symbols\n",
    "    if re.search(r\"[!?.]{3,}\", text) or re.search(r\"[$]{3,}\", text):\n",
    "        return True\n",
    "    \n",
    "    # 8. Foreign/unicode junk (but allow common emojis handled earlier)\n",
    "    if re.search(r\"[^\\x00-\\x7F]+\", text):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Apply spam detection\n",
    "data[\"is_spam\"] = data[\"cleaned_comment\"].apply(is_spam)\n",
    "\n",
    "# Show spam vs non-spam\n",
    "print(\"\\nSpam distribution:\")\n",
    "print(data[\"is_spam\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "53227847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Spam Comments:\n",
      "                                        cleaned_comment\n",
      "705                                you look beautiful üòç\n",
      "7267                   your eyes very much beautiful üòäüòä\n",
      "3352  she was the only one with the special paint on...\n",
      "8855  first time i saw her she was an 80 year old wo...\n",
      "1900           you did understand our india flag a funüòÆ\n",
      "8695                      thank you dear üòò please share\n",
      "1465                   help the eybrow raise i cant üò≠üò≠üò≠\n",
      "4475                                       it was 1970üòÖ\n",
      "5656  dude thats it bro i was literally the girl the...\n",
      "3998  shes naturally awe üòÆ she dont need a wig or ma...\n",
      "7294                        im a girl  what this is toüòÇ\n",
      "1832               why u fine ashl in every single oneüòÇ\n",
      "1714  how is shrek fionaüòÇüòÇüòÇüòÇüòÇüòÇ do you still have a d...\n",
      "628          night look is mind blowing stay blessedüòäüòäüòä\n",
      "6123  even i did the same thing 6 months back  regre...\n",
      "1360                 imagine if henry reacted to this üòÇ\n",
      "2492                       facewash is enough for me üòÇüòÇ\n",
      "5720  just proving that at least one person in the r...\n",
      "1615  not a forehead bronzercontour but the sides be...\n",
      "8410                                        followed  üôå\n"
     ]
    }
   ],
   "source": [
    "# Show a random sample of 20 spam comments\n",
    "print(\"\\nExample Spam Comments:\")\n",
    "print(data[data[\"is_spam\"] == True][[\"cleaned_comment\"]].sample(20, random_state=17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd5e69f",
   "metadata": {},
   "source": [
    "# Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "2ea3d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expanded keyword dictionary\n",
    "\n",
    "phrase_keywords = {\n",
    "    \"skincare\": [\"face mask\", \"face wash\", \"vitamin c\", \"anti aging\", \"anti-aging\", \"sheet mask\", \"eye cream\", \"glow up\"],\n",
    "    \"makeup\":  [\"eye shadow\", \"lip gloss\", \"beauty blender\", \"beautyblender\", \"eye brow pencil\", \"foundation shade\"],\n",
    "    \"fragrance\": [\"eau de parfum\", \"eau de toilette\", \"top notes\", \"base notes\"],\n",
    "    \"service\": [\"shipping\", \"delivery\", \"refund\", \"customer service\", \"order arrived\", \"tracking number\"],\n",
    "    \"price\": [\"expensive\", \"cheap\", \"price\", \"cost\", \"discount\", \"sale\", \"promo\"],\n",
    "    \"question\": [\"how to use\", \"how do i\", \"where can i\", \"what is\", \"which shade\", \"how much\"],\n",
    "    \"praise\": [\"i love\", \"so good\", \"so beautiful\", \"amazing\", \"best product\", \"highly recommend\"],\n",
    "    \"hair\": [\"hair care\", \"hair style\", \"hairstyle\", \"hair cut\", \"hair color\", \"dandruff\"]\n",
    "}\n",
    "\n",
    "word_keywords = {\n",
    "    \"skincare\": [\n",
    "        \"cream\",\"moisturizer\",\"skin\",\"lotion\",\"sunscreen\",\"serum\",\"toner\",\"cleanser\",\n",
    "        \"mask\",\"acne\",\"hydrating\",\"oil\",\"exfoliator\",\"spf\",\"retinol\",\"moisturiser\", \"natural\"\n",
    "    ],\n",
    "    \"makeup\": [\n",
    "        \"lipstick\",\"foundation\",\"eyeliner\",\"mascara\",\"blush\",\"makeup\", \"make up\", \"concealer\",\"primer\",\n",
    "        \"powder\",\"highlighter\",\"brow\",\"palette\",\"bronzer\",\"contour\",\"lashes\",\"lipgloss\",\"eyelash\",\"eyeshadow\",\"shade\"\n",
    "    ],\n",
    "    \"fragrance\": [\n",
    "        \"perfume\",\"scent\",\"fragrance\",\"cologne\",\"parfum\",\"spray\",\"aroma\",\"notes\",\"scented\"\n",
    "    ],\n",
    "    \"service\": [\n",
    "        \"shipping\",\"delivery\",\"refund\",\"return\",\"order\",\"tracking\",\"customer\",\"support\",\"warehouse\",\"arrived\",\"late\"\n",
    "    ],\n",
    "    \"price\": [\n",
    "        \"price\",\"expensive\",\"cheap\",\"discount\",\"sale\",\"deal\",\"cost\",\"worth\"\n",
    "    ],\n",
    "    \"question\": [\n",
    "        \"how\",\"what\",\"where\",\"which\",\"why\",\"help\",\"does\",\"is\",\"can\"  \n",
    "    ],\n",
    "    \"praise\": [\n",
    "        \"love\",\"amazing\",\"beautiful\",\"best\",\"nice\",\"wow\",\"loveit\",\"cute\",\"perfect\",\"recommend\",\"thanks\",\"thankyou\", \"gorgeous\", \"great\", \"cool\", \"pretty\", \"slay\", \"fabulous\"\n",
    "    ],\n",
    "    \"hair\": [\n",
    "        \"hair care\", \"hair style\", \"hairstyle\", \"hair cut\", \"haircuts\", \"hair color\", \"dandruff\", \"hair\", \"scalp\", \"wig\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "3f5bb06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated categorization function\n",
    "def categorize_comment(text):\n",
    "    text = str(text).lower()\n",
    "\n",
    "    # 1. Check phrase-level keywords first\n",
    "    for cat, phrases in phrase_keywords.items():\n",
    "        for phrase in phrases:\n",
    "            if phrase in text:\n",
    "                return cat\n",
    "\n",
    "    # 2. If no phrase found, check single-word keywords\n",
    "    for cat, words in word_keywords.items():\n",
    "        for word in words:\n",
    "            if word in text.split():  # safer: match whole words\n",
    "                return cat\n",
    "\n",
    "    # 3. If nothing matches, label as \"other\"\n",
    "    return \"other\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "03d3d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply categorization\n",
    "data[\"category\"] = data[\"cleaned_comment\"].apply(categorize_comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "287ff78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Category Distribution:\n",
      "category\n",
      "other        2069\n",
      "question     1226\n",
      "praise       1018\n",
      "makeup        386\n",
      "hair          238\n",
      "skincare      231\n",
      "price          40\n",
      "service        21\n",
      "fragrance      12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# See distribution\n",
    "print(\"\\nCategory Distribution:\")\n",
    "print(data[\"category\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "d9609ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Categorized Comments:\n",
      "                                        cleaned_comment  category\n",
      "9683                 you look amazing in all the styles    praise\n",
      "9151                       can u you do curly next time  question\n",
      "159   love your tutorial and how you apply makeup th...    makeup\n",
      "98    truly a super lady how composed confident inte...  question\n",
      "1743  i watched this too many times bcuz she is real...    praise\n",
      "3267  you deserve it bestie btw what about the neck ...  question\n",
      "2266  incredible ill have to try that \\nshare more v...     other\n",
      "3979                                           gorgeous    praise\n",
      "7040  people out there acting like being fat is a cr...  question\n",
      "7967  i literally laughed because it was you üòÇ  also...      hair\n"
     ]
    }
   ],
   "source": [
    "# Sample categorized comments\n",
    "print(\"\\nSample Categorized Comments:\")\n",
    "print(data[[\"cleaned_comment\", \"category\"]].sample(10, random_state=17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "3af92aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        cleaned_comment\n",
      "1724                                   bro 5 m on insta\n",
      "6163               giving weird not a fashion statement\n",
      "6279                       bro looks like carl weathers\n",
      "4736           theyre not women you were born a man sir\n",
      "253   of all the make up you have and then thats my ...\n",
      "4775  she didnt do any thing wrong youre just being ...\n",
      "5730            girl you are talking about boys not men\n",
      "7037  she said it looked like she was punched by the...\n",
      "5866                          346 üòÇ loved this reaction\n",
      "4340               thats fed up i hope i never go blind\n"
     ]
    }
   ],
   "source": [
    "print(data[data[\"category\"] == \"other\"][[\"cleaned_comment\"]].sample(10, random_state=17))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b546dded",
   "metadata": {},
   "source": [
    "# Machine Learning Model (Comments Category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "55c54f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Features and Labels for ML\n",
    "X = data[\"cleaned_comment\"]\n",
    "y = data[\"category\"]  # <-- TARGET VARIABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "7aedfce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train-test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d1ef50d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "4ba6aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "d47f0c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Naive Bayes ===\n",
      "Accuracy: 0.5919923736892279\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   fragrance       0.00      0.00      0.00         2\n",
      "        hair       0.00      0.00      0.00        48\n",
      "      makeup       0.94      0.18      0.30        83\n",
      "       other       0.60      0.93      0.73       420\n",
      "      praise       0.70      0.77      0.73       202\n",
      "       price       0.00      0.00      0.00         6\n",
      "    question       0.38      0.25      0.30       232\n",
      "     service       0.00      0.00      0.00         7\n",
      "    skincare       1.00      0.06      0.12        49\n",
      "\n",
      "    accuracy                           0.59      1049\n",
      "   macro avg       0.40      0.24      0.24      1049\n",
      "weighted avg       0.58      0.59      0.53      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   0   2   0   0   0   0   0]\n",
      " [  0   0   0  13   6   0  29   0   0]\n",
      " [  0   0  15  34  24   0  10   0   0]\n",
      " [  0   0   0 389   6   0  25   0   0]\n",
      " [  0   0   1  23 156   0  22   0   0]\n",
      " [  0   0   0   5   0   0   1   0   0]\n",
      " [  0   0   0 151  23   0  58   0   0]\n",
      " [  0   0   0   5   0   0   2   0   0]\n",
      " [  0   0   0  30   9   0   7   0   3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Machine Learning Models\n",
    "# ==============================\n",
    "\n",
    "# --- Naive Bayes ---\n",
    "nb_clf = MultinomialNB()\n",
    "nb_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_nb = nb_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== Naive Bayes ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(classification_report(y_test, y_pred_nb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "b1a395f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Logistic Regression ===\n",
      "Accuracy: 0.6873212583412774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   fragrance       0.00      0.00      0.00         2\n",
      "        hair       0.71      0.42      0.53        48\n",
      "      makeup       0.88      0.73      0.80        83\n",
      "       other       0.68      0.90      0.77       420\n",
      "      praise       0.82      0.82      0.82       202\n",
      "       price       0.00      0.00      0.00         6\n",
      "    question       0.45      0.32      0.37       232\n",
      "     service       0.00      0.00      0.00         7\n",
      "    skincare       0.88      0.47      0.61        49\n",
      "\n",
      "    accuracy                           0.69      1049\n",
      "   macro avg       0.49      0.41      0.43      1049\n",
      "weighted avg       0.67      0.69      0.67      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   0   0   1   0   1   0   0]\n",
      " [  0  20   0   8   3   0  16   0   1]\n",
      " [  0   0  61  16   3   0   3   0   0]\n",
      " [  0   0   0 378   4   0  37   0   1]\n",
      " [  0   2   2   9 165   0  24   0   0]\n",
      " [  0   0   1   5   0   0   0   0   0]\n",
      " [  0   5   0 127  25   0  74   0   1]\n",
      " [  0   0   0   5   0   0   2   0   0]\n",
      " [  0   1   5  12   1   0   7   0  23]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# --- Logistic Regression ---\n",
    "lr_clf = LogisticRegression(max_iter=1000, random_state=25)\n",
    "lr_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== Logistic Regression ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "aeeaf8eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Random Forest ===\n",
      "Accuracy: 0.7435653002859867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   fragrance       0.00      0.00      0.00         2\n",
      "        hair       0.67      0.77      0.72        48\n",
      "      makeup       0.91      0.93      0.92        83\n",
      "       other       0.72      0.92      0.81       420\n",
      "      praise       0.80      0.90      0.85       202\n",
      "       price       0.50      0.17      0.25         6\n",
      "    question       0.56      0.25      0.35       232\n",
      "     service       1.00      0.29      0.44         7\n",
      "    skincare       0.93      0.76      0.83        49\n",
      "\n",
      "    accuracy                           0.74      1049\n",
      "   macro avg       0.68      0.55      0.57      1049\n",
      "weighted avg       0.72      0.74      0.71      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   0   0   1   0   1   0   0]\n",
      " [  0  37   0   3   3   0   4   0   1]\n",
      " [  0   1  77   1   4   0   0   0   0]\n",
      " [  0   0   2 386   3   1  28   0   0]\n",
      " [  0   3   2   4 182   0  10   0   1]\n",
      " [  0   0   1   4   0   1   0   0   0]\n",
      " [  0  12   0 126  35   0  58   0   1]\n",
      " [  0   1   0   3   0   0   1   2   0]\n",
      " [  0   1   3   6   0   0   2   0  37]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "d:\\pythonsoftware\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# --- Random Forest ---\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=25)\n",
    "rf_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== Random Forest ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "5e5737d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree ===\n",
      "Accuracy: 0.6949475691134414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "   fragrance       0.00      0.00      0.00         2\n",
      "        hair       0.70      0.73      0.71        48\n",
      "      makeup       0.90      0.84      0.87        83\n",
      "       other       0.74      0.81      0.77       420\n",
      "      praise       0.73      0.86      0.79       202\n",
      "       price       0.33      0.17      0.22         6\n",
      "    question       0.40      0.31      0.35       232\n",
      "     service       0.75      0.43      0.55         7\n",
      "    skincare       0.88      0.76      0.81        49\n",
      "\n",
      "    accuracy                           0.69      1049\n",
      "   macro avg       0.60      0.54      0.56      1049\n",
      "weighted avg       0.68      0.69      0.68      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[  0   0   0   0   1   0   1   0   0]\n",
      " [  0  35   0   2   2   0   8   0   1]\n",
      " [  0   1  70   2   7   1   2   0   0]\n",
      " [  1   0   3 339   4   1  71   1   0]\n",
      " [  0   2   3   3 173   0  20   0   1]\n",
      " [  0   0   1   2   0   1   1   0   1]\n",
      " [  0  10   0 102  47   0  71   0   2]\n",
      " [  0   1   0   1   0   0   2   3   0]\n",
      " [  0   1   1   6   3   0   1   0  37]]\n"
     ]
    }
   ],
   "source": [
    "# --- Decision Tree ---\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Initialize Decision Tree classifier\n",
    "dt_clf = DecisionTreeClassifier(random_state=25, max_depth=None, min_samples_split=2)\n",
    "dt_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation\n",
    "print(\"=== Decision Tree ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "815da4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Categories for Sample Comments:\n",
      "['praise' 'skincare' 'hair']\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Predict new comments\n",
    "# ==============================\n",
    "def predict_category(new_comments):\n",
    "    new_tfidf = vectorizer.transform(new_comments)\n",
    "    # you can switch clf to nb_clf, lr_clf, or rf_clf\n",
    "    return lr_clf.predict(new_tfidf)  # example using Logistic Regression\n",
    "\n",
    "sample_comments = [\n",
    "    \"I love this moisturizer, it works wonders\",\n",
    "    \"Your skin is literally glowing\",\n",
    "    \"Your hair is so shiny and curly!\"\n",
    "]\n",
    "\n",
    "print(\"Predicted Categories for Sample Comments:\")\n",
    "print(predict_category(sample_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06ad4d0",
   "metadata": {},
   "source": [
    "# Machine Learning Models (Comments Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "d1700491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# Features and target\n",
    "# ==============================\n",
    "X = data[\"cleaned_comment\"]\n",
    "y = data[\"sentiment\"]  # Target variable: positive, negative, neutral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "035df606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "7420cb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================\n",
    "# TF-IDF Vectorization\n",
    "# ==============================\n",
    "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2), stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a9796c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Decision Tree Sentiment Analysis ===\n",
      "Accuracy: 0.784556720686368\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.66      0.55      0.60       129\n",
      "     neutral       0.71      0.84      0.77       335\n",
      "    positive       0.87      0.80      0.83       585\n",
      "\n",
      "    accuracy                           0.78      1049\n",
      "   macro avg       0.75      0.73      0.73      1049\n",
      "weighted avg       0.79      0.78      0.78      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 71  28  30]\n",
      " [  9 283  43]\n",
      " [ 27  89 469]]\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Decision Tree Classifier\n",
    "# ==============================\n",
    "dt_clf = DecisionTreeClassifier(random_state=42)\n",
    "dt_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_dt = dt_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"=== Decision Tree Sentiment Analysis ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_dt))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "ac07bacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest Sentiment Analysis ===\n",
      "Accuracy: 0.7969494756911344\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.38      0.51       129\n",
      "     neutral       0.70      0.92      0.79       335\n",
      "    positive       0.88      0.82      0.85       585\n",
      "\n",
      "    accuracy                           0.80      1049\n",
      "   macro avg       0.79      0.71      0.72      1049\n",
      "weighted avg       0.81      0.80      0.79      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 49  39  41]\n",
      " [  3 307  25]\n",
      " [ 10  95 480]]\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Random Forest Classifier\n",
    "# ==============================\n",
    "rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "rf_clf.fit(X_train_tfidf, y_train)\n",
    "y_pred_rf = rf_clf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n=== Random Forest Sentiment Analysis ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "d155be3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression Sentiment Analysis ===\n",
      "Accuracy: 0.784556720686368\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.29      0.44       129\n",
      "     neutral       0.71      0.86      0.77       335\n",
      "    positive       0.83      0.85      0.84       585\n",
      "\n",
      "    accuracy                           0.78      1049\n",
      "   macro avg       0.80      0.67      0.69      1049\n",
      "weighted avg       0.80      0.78      0.77      1049\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 38  38  53]\n",
      " [  0 287  48]\n",
      " [  6  81 498]]\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# Logistic Regression\n",
    "# ==============================\n",
    "log_reg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\n=== Logistic Regression Sentiment Analysis ===\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be140f",
   "metadata": {},
   "source": [
    "# KPI Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "561e5461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== KPI Summary ===\n",
      "\n",
      "1. Spam vs Quality (%):\n",
      "is_spam\n",
      "False    80.576226\n",
      "True     19.423774\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "2. Comment Distribution by Category (%):\n",
      "category\n",
      "other        39.477199\n",
      "question     23.392482\n",
      "praise       19.423774\n",
      "makeup        7.365007\n",
      "hair          4.541118\n",
      "skincare      4.407556\n",
      "price         0.763213\n",
      "service       0.400687\n",
      "fragrance     0.228964\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "3. Overall Sentiment Distribution (%):\n",
      "sentiment\n",
      "positive    53.901927\n",
      "neutral     34.249189\n",
      "negative    11.848884\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "4. Sentiment Breakdown per Category (%):\n",
      "sentiment  negative  neutral  positive\n",
      "category                              \n",
      "fragrance     33.33    16.67     50.00\n",
      "hair          18.91    36.97     44.12\n",
      "makeup        12.44    35.23     52.33\n",
      "other         12.61    53.21     34.17\n",
      "praise         1.87     0.98     97.15\n",
      "price         22.50    30.00     47.50\n",
      "question      15.91    32.54     51.55\n",
      "service       14.29    33.33     52.38\n",
      "skincare      16.02    17.32     66.67\n"
     ]
    }
   ],
   "source": [
    "# ==============================\n",
    "# KPI Summary Report\n",
    "# ==============================\n",
    "\n",
    "print(\"\\n=== KPI Summary ===\")\n",
    "\n",
    "# 1. Spam vs Quality\n",
    "spam_dist = data[\"is_spam\"].value_counts(normalize=True) * 100\n",
    "print(\"\\n1. Spam vs Quality (%):\")\n",
    "print(spam_dist)\n",
    "\n",
    "# 2. Distribution by Category\n",
    "category_dist = data[\"category\"].value_counts(normalize=True) * 100\n",
    "print(\"\\n2. Comment Distribution by Category (%):\")\n",
    "print(category_dist)\n",
    "\n",
    "# 3. Sentiment Breakdown (overall)\n",
    "sentiment_dist = data[\"sentiment\"].value_counts(normalize=True) * 100\n",
    "print(\"\\n3. Overall Sentiment Distribution (%):\")\n",
    "print(sentiment_dist)\n",
    "\n",
    "# 4. Sentiment within each Category\n",
    "print(\"\\n4. Sentiment Breakdown per Category (%):\")\n",
    "sentiment_per_cat = pd.crosstab(data[\"category\"], data[\"sentiment\"], normalize=\"index\") * 100\n",
    "print(sentiment_per_cat.round(2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
